{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HWW-Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcastiblancoo/Physics-Analysis-Using-ATLAS-Open-Data-Releases/blob/main/HWW_Analysis-13TeV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HWW Analysis From ATLAS Open Data 13 TeV Release**"
      ],
      "metadata": {
        "id": "yuEXH_aRd5jN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and install necessary extensions:"
      ],
      "metadata": {
        "id": "bvLDrSydepe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!pip install uproot awkward vector numpy matplotlib"
      ],
      "metadata": {
        "id": "nuADDHJteugQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96132f0b-b630-467e-8aab-e7d4b18ecc75"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uproot\n",
            "  Downloading uproot-4.1.9-py2.py3-none-any.whl (301 kB)\n",
            "\u001b[K     |████████████████████████████████| 301 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting awkward\n",
            "  Downloading awkward-1.7.0-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 22.0 MB/s \n",
            "\u001b[?25hCollecting vector\n",
            "  Downloading vector-0.8.4-py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from uproot) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.22 in /usr/local/lib/python3.7/dist-packages (from vector) (4.10.1)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.7/dist-packages (from vector) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from vector) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.22->vector) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=19.0->vector) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Installing collected packages: vector, uproot, awkward\n",
            "Successfully installed awkward-1.7.0 uproot-4.1.9 vector-0.8.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import some tools which will be useful in analysis, and the data set with MC information:"
      ],
      "metadata": {
        "id": "z_5OgJO2e1qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uproot # library for reading .root files\n",
        "import awkward as ak # to represent nested data in columnar format\n",
        "import vector # for 4-momentum calculations\n",
        "import time # to measure time to analyse\n",
        "import math # for mathematical functions such as square root\n",
        "import numpy as np # for numerical calculations such as histogramming\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "from matplotlib.ticker import AutoMinorLocator # for minor ticks\n",
        "\n",
        "import datasetfile # local file containing all dataset IDs, number of events, filter, cross-sections and sums of weights"
      ],
      "metadata": {
        "id": "vGZAM-SRe7r1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA**\n",
        "Access to input files used in this analysis and set the luminosity (fraction) of the DATA we want to analyze:"
      ],
      "metadata": {
        "id": "47bYA6laf_w0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L=10 #fb^{-1}\n",
        "fraction = 0.6 # reduce this is if you want the code to run quicker\n",
        "tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/\" # web address to selected data (Two-Lepton Final State)"
      ],
      "metadata": {
        "id": "wQQPuOutgfZ1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, define the samples to process (**DATA and MC**):"
      ],
      "metadata": {
        "id": "3rnYGGu1lxnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = {\n",
        "\n",
        "    'data': {\n",
        "        'list' : ['data_A','data_B','data_C','data_D'],\n",
        "    },\n",
        "\n",
        "    r'Single top' : { # t-----> 2lep + jets\n",
        "        'list' : ['single_top_tchan','single_antitop_tchan','single_top_schan','single_antitop_schan','single_top_wtchan','single_antitop_wtchan'],\n",
        "        'color' : \"#046865\" # skobeloff\n",
        "    },\n",
        "\n",
        "    r't\\bar{t}$' : { #ttbar ------> 2b-jets + 2lep\n",
        "        'list' : ['ttbar_lep'],\n",
        "        'color' : \"#6b59d3\" # slate blue\n",
        "    },\n",
        "\n",
        "    r'V + jets' : { # W + jets & Z + jets ---> 2lep +sth\n",
        "        'list' : ['Zmumu','Ztautau','Wplusenu','Wplusmunu','Wplustaunu','Wminusenu','Wminusmunu','Wminustaunu','Zee'],\n",
        "        'color' : \"#ffe900\" # middle yellow\n",
        "    },\n",
        "\n",
        "      r'Diboson $WW$' : { # WW\n",
        "        'list' : ['WqqZll','WpqqWmlv','WplvWmqq','WlvZqq','llvv','lvvv','llll', 'ZqqZll', 'lllv'], \n",
        "        'color' : \"#ff0000\" # red\n",
        "    },\n",
        "\n",
        "      r'Higgs ($m_H$ = 125 GeV)' : { # H ----> WW -----> e-nu_e-mu-nu_mu\n",
        "        'list' : ['ggH125_WW2lep','VBFH125_WW2lep','WH125_ZZ4lep','ZH125_ZZ4lep'],\n",
        "        'color' : \"#00cdff\" # vivid sky blue\n",
        "    },\n",
        "\n",
        "    \n",
        "}"
      ],
      "metadata": {
        "id": "-0884BtomD6v"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define the units, taking into account that data is in GeV by default:"
      ],
      "metadata": {
        "id": "ef3taj-679O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GeV=1.0\n",
        "MeV=0.001"
      ],
      "metadata": {
        "id": "pS1OZo9m8HYD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define function to get data from files.\n",
        "\n",
        "The datasets used in this notebook have already been filtered to include at least 2 leptons per event, so that processing is quicker."
      ],
      "metadata": {
        "id": "u6x-2aSJ8MEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_from_files():\n",
        "\n",
        "    data = {} # define empty dictionary to hold awkward arrays\n",
        "    for s in samples: # loop over samples\n",
        "        print('Processing '+s+' samples') # print which sample\n",
        "        frames = [] # define empty list to hold data\n",
        "        for val in samples[s]['list']: # loop over each file\n",
        "            if s == 'data': prefix = \"Data/\" # Data prefix\n",
        "            else: # MC prefix\n",
        "                prefix = \"MC/mc_\"+str(datasetfile.infos[val][\"DSID\"])+\".\"\n",
        "            fileString = tuple_path+prefix+val+\".2lep.root\" # file name to open\n",
        "            print('filestring:',fileString)\n",
        "            temp = read_file(fileString,val) # call the function read_file defined below\n",
        "            frames.append(temp) # append array returned from read_file to list of awkward arrays\n",
        "        data[s] = ak.concatenate(frames) # dictionary entry is concatenated awkward arrays\n",
        "    \n",
        "    return data # return dictionary of awkward arrays"
      ],
      "metadata": {
        "id": "8xUxW2g48SBg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define function to calculate weight of MC event"
      ],
      "metadata": {
        "id": "xFfUBD8z8aez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_weight(xsec_weight, events):\n",
        "    return (\n",
        "        xsec_weight\n",
        "        * events.mcWeight\n",
        "        * events.scaleFactor_PILEUP\n",
        "        * events.scaleFactor_ELE\n",
        "        * events.scaleFactor_MUON \n",
        "        * events.scaleFactor_LepTRIGGER\n",
        "    )"
      ],
      "metadata": {
        "id": "_UPLkEt58by7"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define function to get cross-section weight"
      ],
      "metadata": {
        "id": "Vk3-pO998iT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_xsec_weight(sample):\n",
        "    info = datasetfile.infos[sample] # open infofile\n",
        "    xsec_weight = (L*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) #*1000 to go from fb-1 to pb-1\n",
        "    return xsec_weight # return cross-section weight"
      ],
      "metadata": {
        "id": "oYBEplrY8itB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define function to calculate 2-lepton invariant mass.\n",
        "\n",
        "Note: lep_(pt|eta|phi|E) are variable length lists of lepton momentum components for each event, represented by awkward arrays."
      ],
      "metadata": {
        "id": "yoHu_SfR8_Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def calc_mT_ll(lep_pt, lep_eta, lep_phi, lep_E):\n",
        "    # construct awkward 4-vector array\n",
        "#    pT = vector.awk(ak.zip(dict(pt=lep_pt, eta=lep_eta, phi=lep_phi, E=lep_E)))\n",
        "    # calculate invariant mass of the first 2 leptons \n",
        "    # [:, i] selects the i-th lepton in each event\n",
        "    # .M calculates the invariant mass\n",
        "#    return (pT[:, 0] + pT[:, 1]).M * MeV"
      ],
      "metadata": {
        "id": "NbfEfD1R9DIk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def calc_MET(met_pt, met_eta, met_phi, met_E):\n",
        "    # construct awkward 4-vector array\n",
        "#    MET = vector.awk(ak.zip(dict(pt=met_pt, eta=met_eta, phi=met_phi, E=met_E)))\n",
        "    # calculate invariant mass of the first MET \n",
        "    # [:, i] selects the i-th lepton in each event\n",
        "    # .M calculates the invariant mass\n",
        "#    return (MET[] + MET[]).M * MeV"
      ],
      "metadata": {
        "id": "c8F7lVDGvzpl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def calc_mT(mT_pt, mT_eta, mT_phi, mT_E):\n",
        "#  mT = vector.awk(ak.zip(dict(pt=mT_pt, eta=mT_eta, phi=mT_phi, E=mT_E)))\n",
        "#  return (mT[]).M * MeV"
      ],
      "metadata": {
        "id": "DW94wyaJwaLE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing a cut\n",
        "\n",
        "If you change a cut: Cell -> Run All Below\n",
        "\n",
        "If you change a cut here, you also need to make sure the cut is applied in the \"Applying a cut\" cell."
      ],
      "metadata": {
        "id": "S7L5sXFf9Z8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cut on lepton charge\n",
        "# paper: \"Exactly two isolated, different-flavour opposite-sign leptons (electrons or muons)\"\n",
        "def cut_lep_charge(lep_charge):\n",
        "# throw away when sum of lepton charges is not equal to 0\n",
        "    return lep_charge[:, 0] + lep_charge[:, 1] != 0\n",
        "\n",
        "# cut on lepton type\n",
        "# paper: \"Exactly two isolated, different-flavour opposite-sign leptons (electrons or muons)\"\n",
        "def cut_lep_type(lep_type):\n",
        "# for an electron lep_type is 11\n",
        "# for a muon lep_type is 13\n",
        "# throw away when none of emu\n",
        "    sum_lep_type = lep_type[:, 0] + lep_type[:, 1]\n",
        "    return (sum_lep_type != 24)"
      ],
      "metadata": {
        "id": "idQfmyzU-fRu"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying a cut\n",
        "\n",
        "If you add a cut: Cell -> Run All Below"
      ],
      "metadata": {
        "id": "0xQ7OAJb-oS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(path,sample):\n",
        "    start = time.time() # start the clock\n",
        "    print(\"\\tProcessing: \"+sample) # print which sample is being processed\n",
        "    data_all = [] # define empty list to hold all data for this sample\n",
        "    \n",
        "    # open the tree called mini using a context manager (will automatically close files/resources)\n",
        "    with uproot.open(path + \":mini\") as tree:\n",
        "        numevents = tree.num_entries # number of events\n",
        "        if 'data' not in sample: xsec_weight = get_xsec_weight(sample) # get cross-section weight\n",
        "        for data in tree.iterate(['lep_pt','lep_eta','lep_phi',\n",
        "                                  'lep_E','lep_charge','lep_type',\n",
        "                                  'met_et','met_phi',\n",
        "                                  # add more variables here if you make cuts on them \n",
        "                                  'mcWeight','scaleFactor_PILEUP',\n",
        "                                  'scaleFactor_ELE','scaleFactor_MUON',\n",
        "                                  'scaleFactor_LepTRIGGER'], # variables to calculate Monte Carlo weight\n",
        "                                 library=\"ak\", # choose output type as awkward array\n",
        "                                 entry_stop=numevents*fraction): # process up to numevents*fraction\n",
        "\n",
        "            nIn = len(data) # number of events in this batch\n",
        "\n",
        "            if 'data' not in sample: # only do this for Monte Carlo simulation files\n",
        "                # multiply all Monte Carlo weights and scale factors together to give total weight\n",
        "                data['totalWeight'] = calc_weight(xsec_weight, data)\n",
        "\n",
        "            # cut on lepton charge using the function cut_lep_charge defined above\n",
        "            data = data[~cut_lep_charge(data.lep_charge)]\n",
        "\n",
        "            # cut on lepton type using the function cut_lep_type defined above\n",
        "            data = data[~cut_lep_type(data.lep_type)]\n",
        "            \n",
        "            # construct awkward 4-vectors array for the pair of leptons and the MET:\n",
        "\n",
        "            p2 = vector.awk(ak.zip(dict(pt=data.lep_pt, eta=data.lep_eta, phi=data.lep_phi, E=data.lep_E)))\n",
        "            met= vector.awk(ak.zip(dict(pt=data.met_et, eta=0, phi=data.met_phi, E=data.met_et)))\n",
        "\n",
        "            # calculate invariant mass of first 2 leptons + met\n",
        "            # [:, i] selects the i-th lepton in each event\n",
        "            # .M calculates the invariant mass\n",
        "            mT=(p2[:, 0] + p2[:, 1] + met).M * MeV\n",
        "\n",
        "            # calculation of 2-lepton +MET invariant mass using the function calc_mT defined above\n",
        "            data['mT'] = mT\n",
        "\n",
        "            # array contents can be printed at any stage like this\n",
        "            #print(data)\n",
        "\n",
        "            # array column can be printed at any stage like this\n",
        "            #print(data['lep_pt'])\n",
        "\n",
        "            # multiple array columns can be printed at any stage like this\n",
        "            #print(data[['lep_pt','lep_eta']])\n",
        "\n",
        "            nOut = len(data) # number of events passing cuts in this batch\n",
        "            data_all.append(data) # append array from this batch\n",
        "            elapsed = time.time() - start # time taken to process\n",
        "            print(\"\\t\\t nIn: \"+str(nIn)+\",\\t nOut: \\t\"+str(nOut)+\"\\t in \"+str(round(elapsed,1))+\"s\") # events before and after\n",
        "    \n",
        "    return ak.concatenate(data_all) # return array containing events passing all cuts"
      ],
      "metadata": {
        "id": "e7vbzz8b-45-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where the processing happens"
      ],
      "metadata": {
        "id": "bTeuO7Xn_fIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time() # time at start of whole processing\n",
        "data = get_data_from_files() # process all files\n",
        "elapsed = time.time() - start # time after whole processing\n",
        "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file"
      ],
      "metadata": {
        "id": "EPwiIGtj_jaN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "edafd602-ecf0-4bbf-847d-8720fb5a84df"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data samples\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/Data/data_A.2lep.root\n",
            "\tProcessing: data_A\n",
            "\t\t nIn: 400891,\t nOut: \t16303\t in 12.4s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/Data/data_B.2lep.root\n",
            "\tProcessing: data_B\n",
            "\t\t nIn: 1475622,\t nOut: \t60610\t in 159.3s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/Data/data_C.2lep.root\n",
            "\tProcessing: data_C\n",
            "\t\t nIn: 1807204,\t nOut: \t75305\t in 19.8s\n",
            "\t\t nIn: 345519,\t nOut: \t14236\t in 24.6s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/Data/data_D.2lep.root\n",
            "\tProcessing: data_D\n",
            "\t\t nIn: 1863337,\t nOut: \t78574\t in 152.1s\n",
            "\t\t nIn: 1430900,\t nOut: \t57605\t in 267.4s\n",
            "Processing Single top samples\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_410011.single_top_tchan.2lep.root\n",
            "\tProcessing: single_top_tchan\n",
            "\t\t nIn: 22107,\t nOut: \t7019\t in 6.7s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_410012.single_antitop_tchan.2lep.root\n",
            "\tProcessing: single_antitop_tchan\n",
            "\t\t nIn: 23359,\t nOut: \t7650\t in 7.0s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_410025.single_top_schan.2lep.root\n",
            "\tProcessing: single_top_schan\n",
            "\t\t nIn: 4251,\t nOut: \t1203\t in 6.1s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_410026.single_antitop_schan.2lep.root\n",
            "\tProcessing: single_antitop_schan\n",
            "\t\t nIn: 4507,\t nOut: \t1352\t in 6.3s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_410013.single_top_wtchan.2lep.root\n",
            "\tProcessing: single_top_wtchan\n",
            "\t\t nIn: 99332,\t nOut: \t51215\t in 9.4s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_410014.single_antitop_wtchan.2lep.root\n",
            "\tProcessing: single_antitop_wtchan\n",
            "\t\t nIn: 100700,\t nOut: \t52143\t in 10.2s\n",
            "Processing t\\bar{t}$ samples\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_410000.ttbar_lep.2lep.root\n",
            "\tProcessing: ttbar_lep\n",
            "\t\t nIn: 1568496,\t nOut: \t805835\t in 174.0s\n",
            "\t\t nIn: 177827,\t nOut: \t91612\t in 194.3s\n",
            "Processing V + jets samples\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_361107.Zmumu.2lep.root\n",
            "\tProcessing: Zmumu\n",
            "\t\t nIn: 1717313,\t nOut: \t2556\t in 143.8s\n",
            "\t\t nIn: 1717313,\t nOut: \t2612\t in 276.9s\n",
            "\t\t nIn: 1717313,\t nOut: \t2618\t in 412.4s\n",
            "\t\t nIn: 1717313,\t nOut: \t2682\t in 547.2s\n",
            "\t\t nIn: 1717313,\t nOut: \t2628\t in 684.1s\n",
            "\t\t nIn: 1717313,\t nOut: \t2512\t in 820.0s\n",
            "\t\t nIn: 1717313,\t nOut: \t2630\t in 947.5s\n",
            "\t\t nIn: 1252498,\t nOut: \t1899\t in 1047.0s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_361108.Ztautau.2lep.root\n",
            "\tProcessing: Ztautau\n",
            "\t\t nIn: 109308,\t nOut: \t62011\t in 9.2s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_361100.Wplusenu.2lep.root\n",
            "\tProcessing: Wplusenu\n",
            "\t\t nIn: 24901,\t nOut: \t7133\t in 8.0s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_361101.Wplusmunu.2lep.root\n",
            "\tProcessing: Wplusmunu\n",
            "\t\t nIn: 21110,\t nOut: \t7173\t in 6.8s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_361102.Wplustaunu.2lep.root\n",
            "\tProcessing: Wplustaunu\n",
            "\t\t nIn: 1064,\t nOut: \t318\t in 6.1s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_361103.Wminusenu.2lep.root\n",
            "\tProcessing: Wminusenu\n",
            "\t\t nIn: 19135,\t nOut: \t5748\t in 6.9s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_361104.Wminusmunu.2lep.root\n",
            "\tProcessing: Wminusmunu\n",
            "\t\t nIn: 18184,\t nOut: \t6435\t in 7.1s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_361105.Wminustaunu.2lep.root\n",
            "\tProcessing: Wminustaunu\n",
            "\t\t nIn: 845,\t nOut: \t291\t in 5.2s\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_361106.Zee.2lep.root\n",
            "\tProcessing: Zee\n",
            "\t\t nIn: 1732362,\t nOut: \t2767\t in 151.8s\n",
            "\t\t nIn: 1732362,\t nOut: \t2746\t in 288.6s\n",
            "\t\t nIn: 1732362,\t nOut: \t2813\t in 456.4s\n",
            "\t\t nIn: 1732362,\t nOut: \t2793\t in 591.5s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IncompleteRead",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-0b4025bcc530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# time at start of whole processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_from_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# process all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;31m# time after whole processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print total time taken to process every file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-f8db7646a4e1>\u001b[0m in \u001b[0;36mget_data_from_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mfileString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".2lep.root\"\u001b[0m \u001b[0;31m# file name to open\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filestring:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfileString\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileString\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# call the function read_file defined below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# append array returned from read_file to list of awkward arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dictionary entry is concatenated awkward arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-66762addc8cb>\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(path, sample)\u001b[0m\n\u001b[1;32m     16\u001b[0m                                   'scaleFactor_LepTRIGGER'], # variables to calculate Monte Carlo weight\n\u001b[1;32m     17\u001b[0m                                  \u001b[0mlibrary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ak\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# choose output type as awkward array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                  entry_stop=numevents*fraction): # process up to numevents*fraction\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mnIn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# number of events in this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/behaviors/TBranch.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, expressions, cut, filter_name, filter_typename, filter_branch, aliases, language, entry_start, entry_stop, step_size, decompression_executor, interpretation_executor, library, how, report)\u001b[0m\n\u001b[1;32m   1378\u001b[0m                     \u001b[0mlibrary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m                     \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m                 )\n\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/behaviors/TBranch.py\u001b[0m in \u001b[0;36m_ranges_or_baskets_to_arrays\u001b[0;34m(hasbranches, ranges_or_baskets, branchid_interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, library, arrays, update_ranges_or_baskets)\u001b[0m\n\u001b[1;32m   3519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3520\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3521\u001b[0;31m             \u001b[0muproot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayed_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/source/futures.py\u001b[0m in \u001b[0;36mdelayed_raise\u001b[0;34m(exception_class, exception_value, traceback)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raise exception_class, exception_value, traceback\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/behaviors/TBranch.py\u001b[0m in \u001b[0;36mchunk_to_basket\u001b[0;34m(chunk, branch, basket_num)\u001b[0m\n\u001b[1;32m   3446\u001b[0m                 \u001b[0mhasbranches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3447\u001b[0m                 \u001b[0mhasbranches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3448\u001b[0;31m                 \u001b[0mbranch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3449\u001b[0m             )\n\u001b[1;32m   3450\u001b[0m             \u001b[0moriginal_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange_original_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/model.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(cls, chunk, cursor, context, file, selffile, parent, concrete)\u001b[0m\n\u001b[1;32m    819\u001b[0m             )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m             self.hook_after_read_members(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/models/TBasket.py\u001b[0m in \u001b[0;36mread_members\u001b[0;34m(self, chunk, cursor, context, file)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_members\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fKeylen\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_members\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fCycle\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         ) = cursor.fields(chunk, _tbasket_format1, context)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# skip the class name, name, and title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/source/cursor.py\u001b[0m in \u001b[0;36mfields\u001b[0;34m(self, chunk, format, context, move)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/source/chunk.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, start, stop, cursor, context)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \"\"\"\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m             \u001b[0mlocal_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mlocal_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/source/chunk.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, insist)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \"\"\"\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minsist\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0mrequirement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/source/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mdelayed_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_excinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/source/futures.py\u001b[0m in \u001b[0;36mdelayed_raise\u001b[0;34m(exception_class, exception_value, traceback)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raise exception_class, exception_value, traceback\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/source/futures.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, resource)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_excinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/source/http.py\u001b[0m in \u001b[0;36mtask\u001b[0;34m(resource)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muproot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceFuture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/uproot/source/http.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, connection, start, stop)\u001b[0m\n\u001b[1;32m    252\u001b[0m             )\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mamt\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(0 bytes read, 64391 more expected)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting**\n",
        "\n",
        "If you only want to make a change in plotting: Cell -> Run All Below\n",
        "\n",
        "Define function to plot the data"
      ],
      "metadata": {
        "id": "iN9lGtrz_mLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data(data):\n",
        "\n",
        "    xmin = 50 * GeV\n",
        "    xmax = 210 * GeV\n",
        "    step_size = 5 * GeV\n",
        "\n",
        "    bin_edges = np.arange(start=xmin, # The interval includes this value\n",
        "                     stop=xmax+step_size, # The interval doesn't include this value\n",
        "                     step=step_size ) # Spacing between values\n",
        "    bin_centres = np.arange(start=xmin+step_size/2, # The interval includes this value\n",
        "                            stop=xmax+step_size/2, # The interval doesn't include this value\n",
        "                            step=step_size ) # Spacing between values\n",
        "\n",
        "    data_x,_ = np.histogram(ak.to_numpy(data['data']['mT']), \n",
        "                            bins=bin_edges ) # histogram the data\n",
        "    data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
        "\n",
        "    signal_x = ak.to_numpy(data[r'Higgs ($m_H$ = 125 GeV)']['mT']) # histogram the signal\n",
        "    signal_weights = ak.to_numpy(data[r'Higgs ($m_H$ = 125 GeV)'].totalWeight) # get the weights of the signal events\n",
        "    signal_color = samples[r'Higgs ($m_H$ = 125 GeV)']['color'] # get the colour for the signal bar\n",
        "\n",
        "    mc_x = [] # define list to hold the Monte Carlo histogram entries\n",
        "    mc_weights = [] # define list to hold the Monte Carlo weights\n",
        "    mc_colors = [] # define list to hold the colors of the Monte Carlo bars\n",
        "    mc_labels = [] # define list to hold the legend labels of the Monte Carlo bars\n",
        "\n",
        "    for s in samples: # loop over samples\n",
        "        if s not in ['data', r'Higgs ($m_H$ = 125 GeV)']: # if not data nor signal\n",
        "            mc_x.append( ak.to_numpy(data[s]['mT']) ) # append to the list of Monte Carlo histogram entries\n",
        "            mc_weights.append( ak.to_numpy(data[s].totalWeight) ) # append to the list of Monte Carlo weights\n",
        "            mc_colors.append( samples[s]['color'] ) # append to the list of Monte Carlo bar colors\n",
        "            mc_labels.append( s ) # append to the list of Monte Carlo legend labels\n",
        "    \n",
        "\n",
        "\n",
        "    # *************\n",
        "    # Main plot \n",
        "    # *************\n",
        "    main_axes = plt.gca() # get current axes\n",
        "    \n",
        "    # plot the data points\n",
        "    main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors,\n",
        "                       fmt='ko', # 'k' means black and 'o' is for circles \n",
        "                       label='Data') \n",
        "    \n",
        "    # plot the Monte Carlo bars\n",
        "    mc_heights = main_axes.hist(mc_x, bins=bin_edges, \n",
        "                                weights=mc_weights, stacked=True, \n",
        "                                color=mc_colors, label=mc_labels )\n",
        "    \n",
        "    mc_x_tot = mc_heights[0][-1] # stacked background MC y-axis value\n",
        "    \n",
        "    # calculate MC statistical uncertainty: sqrt(sum w^2)\n",
        "    mc_x_err = np.sqrt(np.histogram(np.hstack(mc_x), bins=bin_edges, weights=np.hstack(mc_weights)**2)[0])\n",
        "    \n",
        "    # plot the signal bar\n",
        "    main_axes.hist(signal_x, bins=bin_edges, bottom=mc_x_tot, \n",
        "                   weights=signal_weights, color=signal_color,\n",
        "                   label=r'Higgs ($m_H$ = 125 GeV)')\n",
        "    \n",
        "    # plot the statistical uncertainty\n",
        "    main_axes.bar(bin_centres, # x\n",
        "                  2*mc_x_err, # heights\n",
        "                  alpha=0.5, # half transparency\n",
        "                  bottom=mc_x_tot-mc_x_err, color='none', \n",
        "                  hatch=\"////\", width=step_size, label='Stat. Unc.' )\n",
        "\n",
        "    # set the x-limit of the main axes\n",
        "    main_axes.set_xlim( left=xmin, right=xmax ) \n",
        "    \n",
        "    # separation of x axis minor ticks\n",
        "    main_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
        "    \n",
        "    # set the axis tick parameters for the main axes\n",
        "    main_axes.tick_params(which='both', # ticks on both x and y axes\n",
        "                          direction='in', # Put ticks inside and outside the axes\n",
        "                          top=True, # draw ticks on the top axis\n",
        "                          right=True ) # draw ticks on right axis\n",
        "    \n",
        "    # x-axis label\n",
        "    main_axes.set_xlabel(r'2-lepton invariant mass $m_{T}$ [GeV]',\n",
        "                        fontsize=13, x=1, horizontalalignment='right' )\n",
        "    \n",
        "    # write y-axis label for main axes\n",
        "    main_axes.set_ylabel('Events / '+str(step_size)+' GeV',\n",
        "                         y=1, horizontalalignment='right') \n",
        "    \n",
        "    # set y-axis limits for main axes\n",
        "    main_axes.set_ylim( bottom=0, top=np.amax(data_x)*1.6 )\n",
        "    \n",
        "    # add minor ticks on y-axis for main axes\n",
        "    main_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
        "\n",
        "    # Add text 'ATLAS Open Data' on plot\n",
        "    plt.text(0.05, # x\n",
        "             0.93, # y\n",
        "             'ATLAS Open Data', # text\n",
        "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
        "             fontsize=13 ) \n",
        "    \n",
        "    # Add text 'for education' on plot\n",
        "    plt.text(0.05, # x\n",
        "            0.88, # y\n",
        "             'By: Brayan E. Castiblanco O.', # text\n",
        "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
        "             style='italic',\n",
        "             fontsize=8 ) \n",
        "    \n",
        "    # Add energy and luminosity\n",
        "    lumi_used = str(L*fraction) # luminosity to write on the plot\n",
        "    plt.text(0.05, # x\n",
        "             0.82, # y\n",
        "             '$\\sqrt{s}$=13 TeV,$\\int$L dt = '+lumi_used+' fb$^{-1}$', # text\n",
        "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
        "    \n",
        "    # Add a label for the analysis carried out\n",
        "    plt.text(0.05, # x\n",
        "             0.76, # y\n",
        "             r'$H \\rightarrow WW^* \\rightarrow e\\nu \\mu\\nu$', # text \n",
        "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
        "\n",
        "    # draw the legend\n",
        "    main_axes.legend( frameon=False ) # no box around the legend\n",
        "    \n",
        "    return"
      ],
      "metadata": {
        "id": "mN8eACIsA4Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the function to plot the data"
      ],
      "metadata": {
        "id": "RkcE0iolDDjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data(data)"
      ],
      "metadata": {
        "id": "vXN7C3ZoDE-P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}