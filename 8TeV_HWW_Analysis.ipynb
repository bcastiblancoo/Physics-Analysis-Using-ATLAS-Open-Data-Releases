{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8TeV-HWW-Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcastiblancoo/Physics-Analysis-Using-ATLAS-Open-Data-Releases/blob/main/8TeV_HWW_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HWW Analysis From ATLAS Open Data 8 TeV Release**"
      ],
      "metadata": {
        "id": "yuEXH_aRd5jN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and install necessary extensions:"
      ],
      "metadata": {
        "id": "bvLDrSydepe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!pip install uproot awkward vector numpy matplotlib"
      ],
      "metadata": {
        "id": "nuADDHJteugQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb6b90d-ea5c-4ed0-8f10-0713f8a62722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: uproot in /usr/local/lib/python3.7/dist-packages (4.1.9)\n",
            "Requirement already satisfied: awkward in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied: vector in /usr/local/lib/python3.7/dist-packages (0.8.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from uproot) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.22 in /usr/local/lib/python3.7/dist-packages (from vector) (4.10.1)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.7/dist-packages (from vector) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from vector) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.22->vector) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=19.0->vector) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import some tools which will be useful in analysis, and the data set with MC information:"
      ],
      "metadata": {
        "id": "z_5OgJO2e1qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uproot # library for reading .root files\n",
        "import awkward as ak # to represent nested data in columnar format\n",
        "import vector # for 4-momentum calculations\n",
        "import time # to measure time to analyse\n",
        "import math # for mathematical functions such as square root\n",
        "import numpy as np # for numerical calculations such as histogramming\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "from matplotlib.ticker import AutoMinorLocator # for minor ticks\n",
        "\n",
        "import infofile8 # local file containing all dataset IDs, number of events, filter, cross-sections and sums of weights"
      ],
      "metadata": {
        "id": "vGZAM-SRe7r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA**\n",
        "Access to input files used in this analysis and set the luminosity (fraction) of the DATA we want to analyze:"
      ],
      "metadata": {
        "id": "47bYA6laf_w0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L=1 #fb^{-1}\n",
        "fraction = 0.6 # reduce this is if you want the code to run quicker\n",
        "tuple_path = \"http://opendata.atlas.cern/release/samples/\" # web address to 8TeV data"
      ],
      "metadata": {
        "id": "wQQPuOutgfZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, define the samples to process (**DATA and MC**):"
      ],
      "metadata": {
        "id": "3rnYGGu1lxnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = {\n",
        "\n",
        "    'data': {\n",
        "        'list' : ['DataMuons','DataEgamma'],\n",
        "    },\n",
        "\n",
        "    r'Single top' : { # t-----> 2lep + jets\n",
        "        'list' : ['stop_tchan_top','stop_tchan_antitop','stop_schan','stop_wtchan'],\n",
        "        'color' : \"#046865\" # skobeloff\n",
        "    },\n",
        "\n",
        "    r't\\bar{t}$' : { #ttbar ------> 2b-jets + 2lep\n",
        "        'list' : ['ttbar_lep', 'ttbar_had'],\n",
        "        'color' : \"#6b59d3\" # slate blue\n",
        "    },\n",
        "\n",
        "    r'Drell-Yann' : { # p + p -----> 2lep + jets\n",
        "        'list' : ['DYeeM08to15', 'DYeeM15to40', 'DYmumuM08to15', 'DYmumuM15to40', 'DYtautauM08to15', 'DYtautauM15to40'],\n",
        "        'color' : \"#ffe900\" # middle yellow\n",
        "    },\n",
        "\n",
        "      r'Diboson $WW$' : { # WW\n",
        "        'list' : ['WW', 'WZ', 'ZZ'], \n",
        "        'color' : \"#ff0000\" # red\n",
        "    },\n",
        "      \n",
        "      r'W' : { # W\n",
        "        'list' : ['WenuJetsBVeto', 'WenuWithB', 'WenuNoJetsBVeto', 'WmunuJetsBVeto', 'WmunuWithB', 'WmunuNoJetsBVeto', 'WtaunuJetsBVeto', 'WtaunuWithB', 'WtaunuNoJetsBVeto'], \n",
        "        'color' : \"#e55934\" #orange soda\n",
        "    },\n",
        "      \n",
        "      r'Z' : { # Z\n",
        "        'list' : ['Zee', 'Zmumu', 'Ztautau'], \n",
        "        'color' : \"#086788\" # Blue Saphire\n",
        "    },\n",
        "    \n",
        "      r'Higgs ($m_H$ = 125 GeV)' : { # H ----> WW -----> e-nu_e-mu-nu_mu\n",
        "        'list' : ['ggH125_WW2lep'],\n",
        "        'color' : \"#00cdff\" # vivid sky blue\n",
        "    },\n",
        "\n",
        "    \n",
        "}"
      ],
      "metadata": {
        "id": "-0884BtomD6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define the units, taking into account that data is in GeV by default:"
      ],
      "metadata": {
        "id": "ef3taj-679O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GeV=1.0\n",
        "MeV=0.001"
      ],
      "metadata": {
        "id": "pS1OZo9m8HYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define function to get data from files.\n",
        "\n",
        "The datasets used in this notebook have already been filtered to include at least 2 leptons per event, so that processing is quicker."
      ],
      "metadata": {
        "id": "u6x-2aSJ8MEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_from_files():\n",
        "\n",
        "    data = {} # define empty dictionary to hold awkward arrays\n",
        "    for s in samples: # loop over samples\n",
        "        print('Processing '+s+' samples') # print which sample\n",
        "        frames = [] # define empty list to hold data\n",
        "        for val in samples[s]['list']: # loop over each file\n",
        "            if s == 'data': prefix = \"Data/\" # Data prefix\n",
        "            else: # MC prefix\n",
        "                prefix = \"MC/mc_\"+str(infofile8.infos[val][\"DSID\"])+\".\"\n",
        "            fileString = tuple_path+prefix+val+\".root\" # file name to open\n",
        "            print('filestring:',fileString)\n",
        "            temp = read_file(fileString,val) # call the function read_file defined below\n",
        "            frames.append(temp) # append array returned from read_file to list of awkward arrays\n",
        "        data[s] = ak.concatenate(frames) # dictionary entry is concatenated awkward arrays\n",
        "    \n",
        "    return data # return dictionary of awkward arrays"
      ],
      "metadata": {
        "id": "8xUxW2g48SBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define function to calculate weight of MC event"
      ],
      "metadata": {
        "id": "xFfUBD8z8aez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_weight(xsec_weight, events):\n",
        "    return (\n",
        "        xsec_weight\n",
        "        * events.mcWeight\n",
        "        * events.scaleFactor_PILEUP\n",
        "        * events.scaleFactor_ELE\n",
        "        * events.scaleFactor_MUON \n",
        "        * events.scaleFactor_LepTRIGGER\n",
        "    )"
      ],
      "metadata": {
        "id": "_UPLkEt58by7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define function to get cross-section weight"
      ],
      "metadata": {
        "id": "Vk3-pO998iT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_xsec_weight(sample):\n",
        "    info = infofile8.infos[sample] # open infofile\n",
        "    xsec_weight = (L*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) #*1000 to go from fb-1 to pb-1\n",
        "    return xsec_weight # return cross-section weight"
      ],
      "metadata": {
        "id": "oYBEplrY8itB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define function to calculate 2-lepton invariant mass.\n",
        "\n",
        "Note: lep_(pt|eta|phi|E) are variable length lists of lepton momentum components for each event, represented by awkward arrays."
      ],
      "metadata": {
        "id": "yoHu_SfR8_Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def calc_mT_ll(lep_pt, lep_eta, lep_phi, lep_E):\n",
        "    # construct awkward 4-vector array\n",
        "#    pT = vector.awk(ak.zip(dict(pt=lep_pt, eta=lep_eta, phi=lep_phi, E=lep_E)))\n",
        "    # calculate invariant mass of the first 2 leptons \n",
        "    # [:, i] selects the i-th lepton in each event\n",
        "    # .M calculates the invariant mass\n",
        "#    return (pT[:, 0] + pT[:, 1]).M * MeV"
      ],
      "metadata": {
        "id": "NbfEfD1R9DIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def calc_MET(met_pt, met_eta, met_phi, met_E):\n",
        "    # construct awkward 4-vector array\n",
        "#    MET = vector.awk(ak.zip(dict(pt=met_pt, eta=met_eta, phi=met_phi, E=met_E)))\n",
        "    # calculate invariant mass of the first MET \n",
        "    # [:, i] selects the i-th lepton in each event\n",
        "    # .M calculates the invariant mass\n",
        "#    return (MET[] + MET[]).M * MeV"
      ],
      "metadata": {
        "id": "c8F7lVDGvzpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def calc_mT(mT_pt, mT_eta, mT_phi, mT_E):\n",
        "#  mT = vector.awk(ak.zip(dict(pt=mT_pt, eta=mT_eta, phi=mT_phi, E=mT_E)))\n",
        "#  return (mT[]).M * MeV"
      ],
      "metadata": {
        "id": "DW94wyaJwaLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing a cut\n",
        "\n",
        "If you change a cut: Cell -> Run All Below\n",
        "\n",
        "If you change a cut here, you also need to make sure the cut is applied in the \"Applying a cut\" cell."
      ],
      "metadata": {
        "id": "S7L5sXFf9Z8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cut on lepton charge\n",
        "# paper: \"Exactly two isolated, different-flavour opposite-sign leptons (electrons or muons)\"\n",
        "def cut_lep_charge(lep_charge):\n",
        "# throw away when sum of lepton charges is not equal to 0\n",
        "    return lep_charge[:, 0] + lep_charge[:, 1] != 0\n",
        "\n",
        "# cut on lepton type\n",
        "# paper: \"Exactly two isolated, different-flavour opposite-sign leptons (electrons or muons)\"\n",
        "def cut_lep_type(lep_type):\n",
        "# for an electron lep_type is 11\n",
        "# for a muon lep_type is 13\n",
        "# throw away when none of emu\n",
        "    sum_lep_type = lep_type[:, 0] + lep_type[:, 1]\n",
        "    return (sum_lep_type != 24)"
      ],
      "metadata": {
        "id": "idQfmyzU-fRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying a cut\n",
        "\n",
        "If you add a cut: Cell -> Run All Below"
      ],
      "metadata": {
        "id": "0xQ7OAJb-oS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(path,sample):\n",
        "    start = time.time() # start the clock\n",
        "    print(\"\\tProcessing: \"+sample) # print which sample is being processed\n",
        "    data_all = [] # define empty list to hold all data for this sample\n",
        "    \n",
        "    # open the tree called mini using a context manager (will automatically close files/resources)\n",
        "    with uproot.open(path + \":mini\") as tree:\n",
        "        numevents = tree.num_entries # number of events\n",
        "        if 'data' not in sample: xsec_weight = get_xsec_weight(sample) # get cross-section weight\n",
        "        for data in tree.iterate(['lep_pt','lep_eta','lep_phi',\n",
        "                                  'lep_E','lep_charge','lep_type',\n",
        "                                  'met_et','met_phi',\n",
        "                                  # add more variables here if you make cuts on them \n",
        "                                  'mcWeight','scaleFactor_PILEUP',\n",
        "                                  'scaleFactor_ELE','scaleFactor_MUON',\n",
        "                                  'scaleFactor_LepTRIGGER'], # variables to calculate Monte Carlo weight\n",
        "                                 library=\"ak\", # choose output type as awkward array\n",
        "                                 entry_stop=numevents*fraction): # process up to numevents*fraction\n",
        "\n",
        "            nIn = len(data) # number of events in this batch\n",
        "\n",
        "            if 'data' not in sample: # only do this for Monte Carlo simulation files\n",
        "                # multiply all Monte Carlo weights and scale factors together to give total weight\n",
        "                data['totalWeight'] = calc_weight(xsec_weight, data)\n",
        "\n",
        "            # cut on lepton charge using the function cut_lep_charge defined above\n",
        "            data = data[~cut_lep_charge(data.lep_charge)]\n",
        "\n",
        "            # cut on lepton type using the function cut_lep_type defined above\n",
        "            data = data[~cut_lep_type(data.lep_type)]\n",
        "            \n",
        "            # construct awkward 4-vectors array for the pair of leptons and the MET:\n",
        "\n",
        "            p2 = vector.awk(ak.zip(dict(pt=data.lep_pt, eta=data.lep_eta, phi=data.lep_phi, E=data.lep_E)))\n",
        "            met= vector.awk(ak.zip(dict(pt=data.met_et, eta=0, phi=data.met_phi, E=data.met_et)))\n",
        "\n",
        "            # calculate invariant mass of first 2 leptons + met\n",
        "            # [:, i] selects the i-th lepton in each event\n",
        "            # .M calculates the invariant mass\n",
        "            mT=(p2[:, 0] + p2[:, 1] + met).M * MeV\n",
        "\n",
        "            # calculation of 2-lepton +MET invariant mass using the function calc_mT defined above\n",
        "            data['mT'] = mT\n",
        "\n",
        "            # array contents can be printed at any stage like this\n",
        "            #print(data)\n",
        "\n",
        "            # array column can be printed at any stage like this\n",
        "            #print(data['lep_pt'])\n",
        "\n",
        "            # multiple array columns can be printed at any stage like this\n",
        "            #print(data[['lep_pt','lep_eta']])\n",
        "\n",
        "            nOut = len(data) # number of events passing cuts in this batch\n",
        "            data_all.append(data) # append array from this batch\n",
        "            elapsed = time.time() - start # time taken to process\n",
        "            print(\"\\t\\t nIn: \"+str(nIn)+\",\\t nOut: \\t\"+str(nOut)+\"\\t in \"+str(round(elapsed,1))+\"s\") # events before and after\n",
        "    \n",
        "    return ak.concatenate(data_all) # return array containing events passing all cuts"
      ],
      "metadata": {
        "id": "e7vbzz8b-45-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where the processing happens"
      ],
      "metadata": {
        "id": "bTeuO7Xn_fIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time() # time at start of whole processing\n",
        "data = get_data_from_files() # process all files\n",
        "elapsed = time.time() - start # time after whole processing\n",
        "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file"
      ],
      "metadata": {
        "id": "EPwiIGtj_jaN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "d8a2ce73-d938-4edd-faaa-bbbe9d0b3f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data samples\n",
            "filestring: http://opendata.atlas.cern/release/samples/Data/DataMuons.root\n",
            "\tProcessing: DataMuons\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0b4025bcc530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# time at start of whole processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_from_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# process all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;31m# time after whole processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print total time taken to process every file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-aac9187c5166>\u001b[0m in \u001b[0;36mget_data_from_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mfileString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".root\"\u001b[0m \u001b[0;31m# file name to open\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filestring:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfileString\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileString\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# call the function read_file defined below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# append array returned from read_file to list of awkward arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dictionary entry is concatenated awkward arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-66762addc8cb>\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(path, sample)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0muproot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\":mini\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnumevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_entries\u001b[0m \u001b[0;31m# number of events\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'data'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxsec_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_xsec_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get cross-section weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         for data in tree.iterate(['lep_pt','lep_eta','lep_phi',\n\u001b[1;32m     11\u001b[0m                                   \u001b[0;34m'lep_E'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lep_charge'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lep_type'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-cb23249a044d>\u001b[0m in \u001b[0;36mget_xsec_weight\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_xsec_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfofile8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# open infofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mxsec_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"xsec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sumw\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"red_eff\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#*1000 to go from fb-1 to pb-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mxsec_weight\u001b[0m \u001b[0;31m# return cross-section weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'DataMuons'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting**\n",
        "\n",
        "If you only want to make a change in plotting: Cell -> Run All Below\n",
        "\n",
        "Define function to plot the data"
      ],
      "metadata": {
        "id": "iN9lGtrz_mLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data(data):\n",
        "\n",
        "    xmin = 50 * GeV\n",
        "    xmax = 210 * GeV\n",
        "    step_size = 5 * GeV\n",
        "\n",
        "    bin_edges = np.arange(start=xmin, # The interval includes this value\n",
        "                     stop=xmax+step_size, # The interval doesn't include this value\n",
        "                     step=step_size ) # Spacing between values\n",
        "    bin_centres = np.arange(start=xmin+step_size/2, # The interval includes this value\n",
        "                            stop=xmax+step_size/2, # The interval doesn't include this value\n",
        "                            step=step_size ) # Spacing between values\n",
        "\n",
        "    data_x,_ = np.histogram(ak.to_numpy(data['data']['mT']), \n",
        "                            bins=bin_edges ) # histogram the data\n",
        "    data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
        "\n",
        "    signal_x = ak.to_numpy(data[r'Higgs ($m_H$ = 125 GeV)']['mT']) # histogram the signal\n",
        "    signal_weights = ak.to_numpy(data[r'Higgs ($m_H$ = 125 GeV)'].totalWeight) # get the weights of the signal events\n",
        "    signal_color = samples[r'Higgs ($m_H$ = 125 GeV)']['color'] # get the colour for the signal bar\n",
        "\n",
        "    mc_x = [] # define list to hold the Monte Carlo histogram entries\n",
        "    mc_weights = [] # define list to hold the Monte Carlo weights\n",
        "    mc_colors = [] # define list to hold the colors of the Monte Carlo bars\n",
        "    mc_labels = [] # define list to hold the legend labels of the Monte Carlo bars\n",
        "\n",
        "    for s in samples: # loop over samples\n",
        "        if s not in ['data', r'Higgs ($m_H$ = 125 GeV)']: # if not data nor signal\n",
        "            mc_x.append( ak.to_numpy(data[s]['mT']) ) # append to the list of Monte Carlo histogram entries\n",
        "            mc_weights.append( ak.to_numpy(data[s].totalWeight) ) # append to the list of Monte Carlo weights\n",
        "            mc_colors.append( samples[s]['color'] ) # append to the list of Monte Carlo bar colors\n",
        "            mc_labels.append( s ) # append to the list of Monte Carlo legend labels\n",
        "    \n",
        "\n",
        "\n",
        "    # *************\n",
        "    # Main plot \n",
        "    # *************\n",
        "    main_axes = plt.gca() # get current axes\n",
        "    \n",
        "    # plot the data points\n",
        "    main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors,\n",
        "                       fmt='ko', # 'k' means black and 'o' is for circles \n",
        "                       label='Data') \n",
        "    \n",
        "    # plot the Monte Carlo bars\n",
        "    mc_heights = main_axes.hist(mc_x, bins=bin_edges, \n",
        "                                weights=mc_weights, stacked=True, \n",
        "                                color=mc_colors, label=mc_labels )\n",
        "    \n",
        "    mc_x_tot = mc_heights[0][-1] # stacked background MC y-axis value\n",
        "    \n",
        "    # calculate MC statistical uncertainty: sqrt(sum w^2)\n",
        "    mc_x_err = np.sqrt(np.histogram(np.hstack(mc_x), bins=bin_edges, weights=np.hstack(mc_weights)**2)[0])\n",
        "    \n",
        "    # plot the signal bar\n",
        "    main_axes.hist(signal_x, bins=bin_edges, bottom=mc_x_tot, \n",
        "                   weights=signal_weights, color=signal_color,\n",
        "                   label=r'Higgs ($m_H$ = 125 GeV)')\n",
        "    \n",
        "    # plot the statistical uncertainty\n",
        "    main_axes.bar(bin_centres, # x\n",
        "                  2*mc_x_err, # heights\n",
        "                  alpha=0.5, # half transparency\n",
        "                  bottom=mc_x_tot-mc_x_err, color='none', \n",
        "                  hatch=\"////\", width=step_size, label='Stat. Unc.' )\n",
        "\n",
        "    # set the x-limit of the main axes\n",
        "    main_axes.set_xlim( left=xmin, right=xmax ) \n",
        "    \n",
        "    # separation of x axis minor ticks\n",
        "    main_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
        "    \n",
        "    # set the axis tick parameters for the main axes\n",
        "    main_axes.tick_params(which='both', # ticks on both x and y axes\n",
        "                          direction='in', # Put ticks inside and outside the axes\n",
        "                          top=True, # draw ticks on the top axis\n",
        "                          right=True ) # draw ticks on right axis\n",
        "    \n",
        "    # x-axis label\n",
        "    main_axes.set_xlabel(r'2-lepton invariant mass $m_{T}$ [GeV]',\n",
        "                        fontsize=13, x=1, horizontalalignment='right' )\n",
        "    \n",
        "    # write y-axis label for main axes\n",
        "    main_axes.set_ylabel('Events / '+str(step_size)+' GeV',\n",
        "                         y=1, horizontalalignment='right') \n",
        "    \n",
        "    # set y-axis limits for main axes\n",
        "    main_axes.set_ylim( bottom=0, top=np.amax(data_x)*1.6 )\n",
        "    \n",
        "    # add minor ticks on y-axis for main axes\n",
        "    main_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
        "\n",
        "    # Add text 'ATLAS Open Data' on plot\n",
        "    plt.text(0.05, # x\n",
        "             0.93, # y\n",
        "             'ATLAS Open Data', # text\n",
        "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
        "             fontsize=13 ) \n",
        "    \n",
        "    # Add text 'for education' on plot\n",
        "    plt.text(0.05, # x\n",
        "            0.88, # y\n",
        "             'By: Brayan E. Castiblanco O.', # text\n",
        "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
        "             style='italic',\n",
        "             fontsize=8 ) \n",
        "    \n",
        "    # Add energy and luminosity\n",
        "    lumi_used = str(L*fraction) # luminosity to write on the plot\n",
        "    plt.text(0.05, # x\n",
        "             0.82, # y\n",
        "             '$\\sqrt{s}$=13 TeV,$\\int$L dt = '+lumi_used+' fb$^{-1}$', # text\n",
        "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
        "    \n",
        "    # Add a label for the analysis carried out\n",
        "    plt.text(0.05, # x\n",
        "             0.76, # y\n",
        "             r'$H \\rightarrow WW^* \\rightarrow e\\nu \\mu\\nu$', # text \n",
        "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
        "\n",
        "    # draw the legend\n",
        "    main_axes.legend( frameon=False ) # no box around the legend\n",
        "    \n",
        "    return"
      ],
      "metadata": {
        "id": "mN8eACIsA4Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the function to plot the data"
      ],
      "metadata": {
        "id": "RkcE0iolDDjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data(data)"
      ],
      "metadata": {
        "id": "vXN7C3ZoDE-P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}