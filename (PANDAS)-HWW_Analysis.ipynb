{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HWW-Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcastiblancoo/Physics-Analysis-Using-ATLAS-Open-Data-Releases/blob/main/(PANDAS)-HWW_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HWW Analysis From ATLAS Open Data 13 TeV Release**"
      ],
      "metadata": {
        "id": "yuEXH_aRd5jN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and install necessary extensions:"
      ],
      "metadata": {
        "id": "bvLDrSydepe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!pip install uproot3 vector numpy matplotlib #awkward"
      ],
      "metadata": {
        "id": "nuADDHJteugQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef83320d-9ae1-4ee1-a6d0-ee9f804294eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uproot3\n",
            "  Downloading uproot3-3.14.4-py3-none-any.whl (117 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▉                             | 10 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 20 kB 38.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 30 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 40 kB 21.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 51 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 61 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 71 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 81 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 92 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 102 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 112 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 117 kB 12.3 MB/s \n",
            "\u001b[?25hCollecting vector\n",
            "  Downloading vector-0.8.4-py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 75.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from uproot3) (4.2.4)\n",
            "Collecting uproot3-methods\n",
            "  Downloading uproot3_methods-0.10.1-py3-none-any.whl (32 kB)\n",
            "Collecting awkward0\n",
            "  Downloading awkward0-0.15.5-py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.7/dist-packages (from vector) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from vector) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.22 in /usr/local/lib/python3.7/dist-packages (from vector) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.22->vector) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=19.0->vector) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Installing collected packages: awkward0, uproot3-methods, vector, uproot3\n",
            "Successfully installed awkward0-0.15.5 uproot3-3.14.4 uproot3-methods-0.10.1 vector-0.8.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import some tools which will be useful in analysis, and the data set with MC information:"
      ],
      "metadata": {
        "id": "z_5OgJO2e1qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uproot3 # library for reading .root files\n",
        "import pandas as pd # to represent nested data in columnar format\n",
        "#import awkward as ak\n",
        "import vector # for 4-momentum calculations\n",
        "import time # to measure time to analyse\n",
        "import math # for mathematical functions such as square root\n",
        "import numpy as np # for numerical calculations such as histogramming\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "from matplotlib.ticker import AutoMinorLocator # for minor ticks\n",
        "\n",
        "import datasetfile # local file containing all dataset IDs, number of events, filter, cross-sections and sums of weights"
      ],
      "metadata": {
        "id": "vGZAM-SRe7r1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA**\n",
        "Access to input files used in this analysis and set the luminosity (fraction) of the DATA we want to analyze:"
      ],
      "metadata": {
        "id": "47bYA6laf_w0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L=10 #fb^{-1}\n",
        "fraction = 1.0 # reduce this is if you want the code to run quicker\n",
        "tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/\" # web address to selected data (Two-Lepton Final State)"
      ],
      "metadata": {
        "id": "wQQPuOutgfZ1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, define the samples to process (**DATA and MC**):"
      ],
      "metadata": {
        "id": "3rnYGGu1lxnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = {\n",
        "\n",
        "    'data': {\n",
        "        'list' : ['data_A','data_B','data_C','data_D'],\n",
        "    },\n",
        "\n",
        "    r'Single top' : { # t-----> 2lep + jets\n",
        "        'list' : ['single_top_tchan','single_antitop_tchan','single_top_schan','single_antitop_schan','single_top_wtchan','single_antitop_wtchan'],\n",
        "        'color' : \"#046865\" # skobeloff\n",
        "    },\n",
        "\n",
        "    r't\\bar{t}$' : { #ttbar ------> 2b-jets + 2lep\n",
        "        'list' : ['ttbar_lep'],\n",
        "        'color' : \"#6b59d3\" # slate blue\n",
        "    },\n",
        "\n",
        "    r'V + jets' : { # W + jets & Z + jets ---> 2lep +sth\n",
        "        'list' : ['Zmumu','Ztautau','Wplusenu','Wplusmunu','Wplustaunu','Wminusenu','Wminusmunu','Wminustaunu','Zee'],\n",
        "        'color' : \"#ffe900\" # middle yellow\n",
        "    },\n",
        "\n",
        "      r'Diboson $WW$' : { # WW\n",
        "        'list' : ['WqqZll','WpqqWmlv','WplvWmqq','WlvZqq','llvv','lvvv','llll', 'ZqqZll', 'lllv'], \n",
        "        'color' : \"#ff0000\" # red\n",
        "    },\n",
        "\n",
        "      r'Higgs ($m_H$ = 125 GeV)' : { # H ----> WW -----> e-nu_e-mu-nu_mu\n",
        "        'list' : ['ggH125_WW2lep','VBFH125_WW2lep','WH125_ZZ4lep','ZH125_ZZ4lep'],\n",
        "        'color' : \"#00cdff\" # vivid sky blue\n",
        "    },\n",
        "\n",
        "    \n",
        "}"
      ],
      "metadata": {
        "id": "-0884BtomD6v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define the units, taking into account that data is in GeV by default:"
      ],
      "metadata": {
        "id": "ef3taj-679O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GeV=1.0\n",
        "MeV=0.001"
      ],
      "metadata": {
        "id": "pS1OZo9m8HYD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define function to get data from files.\n",
        "\n",
        "The datasets used in this notebook have already been filtered to include at least 2 leptons per event, so that processing is quicker."
      ],
      "metadata": {
        "id": "u6x-2aSJ8MEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_from_files():\n",
        "\n",
        "    data = {} # define empty dictionary to hold awkward arrays\n",
        "    for s in samples: # loop over samples\n",
        "        print('Processing '+s+' samples') # print which sample\n",
        "        frames = [] # define empty list to hold data\n",
        "        for val in samples[s]['list']: # loop over each file\n",
        "            if s == 'data': prefix = \"Data/\" # Data prefix\n",
        "            else: # MC prefix\n",
        "                prefix = \"MC/mc_\"+str(datasetfile.infos[val][\"DSID\"])+\".\"\n",
        "            fileString = tuple_path+prefix+val+\".2lep.root\" # file name to open\n",
        "            print('filestring:',fileString)\n",
        "            temp = read_file(fileString,val) # call the function read_file defined below\n",
        "            frames.append(temp) # append dataframe returned from read_file to list of dataframes\n",
        "        data[s] = pd.concat(frames) # dictionary entry is concatenated awkward arrays\n",
        "    \n",
        "    return data # return dictionary of awkward arrays"
      ],
      "metadata": {
        "id": "8xUxW2g48SBg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define function to calculate weight of MC event"
      ],
      "metadata": {
        "id": "xFfUBD8z8aez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_weight(xsec_weight, events):\n",
        "    return (\n",
        "        xsec_weight\n",
        "        * events.mcWeight\n",
        "        * events.scaleFactor_PILEUP\n",
        "        * events.scaleFactor_ELE\n",
        "        * events.scaleFactor_MUON \n",
        "        * events.scaleFactor_LepTRIGGER\n",
        "    )"
      ],
      "metadata": {
        "id": "_UPLkEt58by7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define function to get cross-section weight"
      ],
      "metadata": {
        "id": "Vk3-pO998iT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_xsec_weight(sample):\n",
        "    info = datasetfile.infos[sample] # open infofile\n",
        "    xsec_weight = (L*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) #*1000 to go from fb-1 to pb-1\n",
        "    return xsec_weight # return cross-section weight"
      ],
      "metadata": {
        "id": "oYBEplrY8itB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define function to calculate 2-lepton invariant mass.\n",
        "\n",
        "Note: lep_(pt|eta|phi|E) are variable length lists of lepton momentum components for each event, represented by awkward arrays."
      ],
      "metadata": {
        "id": "yoHu_SfR8_Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def calc_mT_ll(lep_pt, lep_eta, lep_phi, lep_E):\n",
        "    # construct awkward 4-vector array\n",
        "#    pT = vector.awk(ak.zip(dict(pt=lep_pt, eta=lep_eta, phi=lep_phi, E=lep_E)))\n",
        "    # calculate invariant mass of the first 2 leptons \n",
        "    # [:, i] selects the i-th lepton in each event\n",
        "    # .M calculates the invariant mass\n",
        "#    return (pT[:, 0] + pT[:, 1]).M * MeV"
      ],
      "metadata": {
        "id": "NbfEfD1R9DIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def calc_MET(met_pt, met_eta, met_phi, met_E):\n",
        "    # construct awkward 4-vector array\n",
        "#    MET = vector.awk(ak.zip(dict(pt=met_pt, eta=met_eta, phi=met_phi, E=met_E)))\n",
        "    # calculate invariant mass of the first MET \n",
        "    # [:, i] selects the i-th lepton in each event\n",
        "    # .M calculates the invariant mass\n",
        "#    return (MET[] + MET[]).M * MeV"
      ],
      "metadata": {
        "id": "c8F7lVDGvzpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def calc_mT(mT_pt, mT_eta, mT_phi, mT_E):\n",
        "#  mT = vector.awk(ak.zip(dict(pt=mT_pt, eta=mT_eta, phi=mT_phi, E=mT_E)))\n",
        "#  return (mT[]).M * MeV"
      ],
      "metadata": {
        "id": "DW94wyaJwaLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing a cut\n",
        "\n",
        "If you change a cut: Cell -> Run All Below\n",
        "\n",
        "If you change a cut here, you also need to make sure the cut is applied in the \"Applying a cut\" cell."
      ],
      "metadata": {
        "id": "S7L5sXFf9Z8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cut on lepton charge\n",
        "# paper: \"Exactly two isolated, different-flavour opposite-sign leptons (electrons or muons)\"\n",
        "def cut_lep_charge(lep_charge):\n",
        "# throw away when sum of lepton charges is not equal to 0\n",
        "    return lep_charge[:, 0] + lep_charge[:, 1] != 0\n",
        "\n",
        "# cut on lepton type\n",
        "# paper: \"Exactly two isolated, different-flavour opposite-sign leptons (electrons or muons)\"\n",
        "def cut_lep_type(lep_type):\n",
        "# for an electron lep_type is 11\n",
        "# for a muon lep_type is 13\n",
        "# throw away when none of emu\n",
        "    sum_lep_type = lep_type[:, 0] + lep_type[:, 1]\n",
        "    return (sum_lep_type != 24)"
      ],
      "metadata": {
        "id": "idQfmyzU-fRu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying a cut\n",
        "\n",
        "If you add a cut: Cell -> Run All Below"
      ],
      "metadata": {
        "id": "0xQ7OAJb-oS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(path,sample):\n",
        "    start = time.time() # start the clock\n",
        "    print(\"\\tProcessing: \"+sample) # print which sample is being processed\n",
        "    data_all = pd.DataFrame() # define empty pandas DataFrame to hold all data for this sample\n",
        "    tree = uproot3.open(path)[\"mini\"] # open the tree called mini\n",
        "    numevents = uproot3.numentries(path, \"mini\") # number of events\n",
        "    if 'data' not in sample: xsec_weight = get_xsec_weight(sample) # get cross-section weight\n",
        "    for data in tree.iterate(['lep_pt','lep_eta','lep_phi',\n",
        "                              'lep_E','lep_charge','lep_type',\n",
        "                              'met_et','met_phi',\n",
        "                              # add more variables here if you make cuts on them \n",
        "                              'mcWeight','scaleFactor_PILEUP',\n",
        "                              'scaleFactor_ELE','scaleFactor_MUON',\n",
        "                              'scaleFactor_LepTRIGGER'], # variables to calculate Monte Carlo weight\n",
        "                             outputtype = pd.DataFrame, # choose output type as pandas DataFra\n",
        "                             entry_stop=numevents*fraction): # process up to numevents*fraction\n",
        "                             \n",
        "                            \n",
        "            nIn = len(data) # number of events in this batch\n",
        "\n",
        "            if 'data' not in sample: # only do this for Monte Carlo simulation files\n",
        "                # multiply all Monte Carlo weights and scale factors together to give total weight\n",
        "                data['totalWeight'] = calc_weight(xsec_weight, data)\n",
        "\n",
        "            # cut on lepton charge using the function cut_lep_charge defined above\n",
        "            data = data[~cut_lep_charge(data.lep_charge)]\n",
        "\n",
        "            # cut on lepton type using the function cut_lep_type defined above\n",
        "            data = data[~cut_lep_type(data.lep_type)]\n",
        "            \n",
        "            # construct awkward 4-vectors array for the pair of leptons and the MET:\n",
        "\n",
        "            #p2 = vector.awk(ak.zip(dict(pt=data.lep_pt, eta=data.lep_eta, phi=data.lep_phi, E=data.lep_E)))\n",
        "            #met= vector.awk(ak.zip(dict(pt=data.met_et, eta=0, phi=data.met_phi, E=data.met_et)))\n",
        "\n",
        "            #With numpay:\n",
        "            lispt1=[data.lep_pt[0],data.lep_eta[0],data.lep_phi[0],data.lep_E[0]]\n",
        "            lispt2=[data.lep_pt[1],data.lep_eta[1],data.lep_phi[1],data.lep_E[1]]\n",
        "            pl1=np.array(lispt1)\n",
        "            pl2=np.array(lispt2)\n",
        "            p2=pl1+pl2\n",
        "            el1=data.lep_E[0]\n",
        "            el2=data.lep_E[1]\n",
        "            e2=el1+el2\n",
        "\n",
        "            liset=[data.met_et,0,data.met_phi,data.met_et]\n",
        "            pmet=np.array(liset)\n",
        "            met=data.met_et\n",
        "\n",
        "            # calculate invariant mass of first 2 leptons + met\n",
        "            # [:, i] selects the i-th lepton in each event\n",
        "            # .M calculates the invariant mass\n",
        "            mT=math.sqrt((e2+met)**2-abs(p2+pmet))* MeV\n",
        "\n",
        "            # calculation of 2-lepton +MET invariant mass using the function calc_mT defined above\n",
        "            data['mT'] = mT\n",
        "\n",
        "            # array contents can be printed at any stage like this\n",
        "            #print(data)\n",
        "\n",
        "            # array column can be printed at any stage like this\n",
        "            #print(data['lep_pt'])\n",
        "\n",
        "            # multiple array columns can be printed at any stage like this\n",
        "            #print(data[['lep_pt','lep_eta']])\n",
        "\n",
        "            nOut = len(data) # number of events passing cuts in this batch\n",
        "            data_all = data_all.append(data) # append dataframe from this batch to the dataframe for the whole sample\n",
        "            elapsed = time.time() - start # time taken to process\n",
        "            print(\"\\t\\t nIn: \"+str(nIn)+\",\\t nOut: \\t\"+str(nOut)+\"\\t in \"+str(round(elapsed,1))+\"s\") # events before and after\n",
        "    \n",
        "    return data_all # return dataframe containing events passing all cuts"
      ],
      "metadata": {
        "id": "e7vbzz8b-45-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where the processing happens"
      ],
      "metadata": {
        "id": "bTeuO7Xn_fIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time() # time at start of whole processing\n",
        "data = get_data_from_files() # process all files\n",
        "elapsed = time.time() - start # time after whole processing\n",
        "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file"
      ],
      "metadata": {
        "id": "EPwiIGtj_jaN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "9159b46c-e806-4034-d51d-17c3cf247e3f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data samples\n",
            "filestring: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/Data/data_A.2lep.root\n",
            "\tProcessing: data_A\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0b4025bcc530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# time at start of whole processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_from_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# process all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;31m# time after whole processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print total time taken to process every file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2c3ef8cf320c>\u001b[0m in \u001b[0;36mget_data_from_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mfileString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".2lep.root\"\u001b[0m \u001b[0;31m# file name to open\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filestring:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfileString\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileString\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# call the function read_file defined below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# append dataframe returned from read_file to list of dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dictionary entry is concatenated awkward arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-2d1ad4d31988>\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(path, sample)\u001b[0m\n\u001b[1;32m     14\u001b[0m                               'scaleFactor_LepTRIGGER'], # variables to calculate Monte Carlo weight\n\u001b[1;32m     15\u001b[0m                              \u001b[0moutputtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# choose output type as pandas DataFra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                              entry_stop=numevents*fraction): # process up to numevents*fraction\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: iterate() got an unexpected keyword argument 'entry_stop'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting**\n",
        "\n",
        "If you only want to make a change in plotting: Cell -> Run All Below\n",
        "\n",
        "Define function to plot the data"
      ],
      "metadata": {
        "id": "iN9lGtrz_mLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data(data):\n",
        "\n",
        "    xmin = 50 * GeV\n",
        "    xmax = 210 * GeV\n",
        "    step_size = 5 * GeV\n",
        "\n",
        "    bin_edges = np.arange(start=xmin, # The interval includes this value\n",
        "                     stop=xmax+step_size, # The interval doesn't include this value\n",
        "                     step=step_size ) # Spacing between values\n",
        "    bin_centres = np.arange(start=xmin+step_size/2, # The interval includes this value\n",
        "                            stop=xmax+step_size/2, # The interval doesn't include this value\n",
        "                            step=step_size ) # Spacing between values\n",
        "\n",
        "    data_x,_ = np.histogram(pd.DataFrame(data['data']['mT']).to_numpy()), \n",
        "                            bins=bin_edges ) # histogram the data\n",
        "    data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
        "\n",
        "    signal_x = pd.DataFrame(data[r'Higgs ($m_H$ = 125 GeV)']['mT']).to_numpy() # histogram the signal\n",
        "    signal_weights = pd.DataFrame(data[r'Higgs ($m_H$ = 125 GeV)'].totalWeight).to_numpy() # get the weights of the signal events\n",
        "    signal_color = samples[r'Higgs ($m_H$ = 125 GeV)']['color'] # get the colour for the signal bar\n",
        "\n",
        "    mc_x = [] # define list to hold the Monte Carlo histogram entries\n",
        "    mc_weights = [] # define list to hold the Monte Carlo weights\n",
        "    mc_colors = [] # define list to hold the colors of the Monte Carlo bars\n",
        "    mc_labels = [] # define list to hold the legend labels of the Monte Carlo bars\n",
        "\n",
        "    for s in samples: # loop over samples\n",
        "        if s not in ['data', r'Higgs ($m_H$ = 125 GeV)']: # if not data nor signal\n",
        "            mc_x.append( pd.DataFrame(data[s]['mT']).tp_numpy() ) # append to the list of Monte Carlo histogram entries\n",
        "            mc_weights.append( pd.DataFrame(data[s].totalWeight).to_numpy() ) # append to the list of Monte Carlo weights\n",
        "            mc_colors.append( samples[s]['color'] ) # append to the list of Monte Carlo bar colors\n",
        "            mc_labels.append( s ) # append to the list of Monte Carlo legend labels\n",
        "    \n",
        "\n",
        "\n",
        "    # *************\n",
        "    # Main plot \n",
        "    # *************\n",
        "    main_axes = plt.gca() # get current axes\n",
        "    \n",
        "    # plot the data points\n",
        "    main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors,\n",
        "                       fmt='ko', # 'k' means black and 'o' is for circles \n",
        "                       label='Data') \n",
        "    \n",
        "    # plot the Monte Carlo bars\n",
        "    mc_heights = main_axes.hist(mc_x, bins=bin_edges, \n",
        "                                weights=mc_weights, stacked=True, \n",
        "                                color=mc_colors, label=mc_labels )\n",
        "    \n",
        "    mc_x_tot = mc_heights[0][-1] # stacked background MC y-axis value\n",
        "    \n",
        "    # calculate MC statistical uncertainty: sqrt(sum w^2)\n",
        "    mc_x_err = np.sqrt(np.histogram(np.hstack(mc_x), bins=bin_edges, weights=np.hstack(mc_weights)**2)[0])\n",
        "    \n",
        "    # plot the signal bar\n",
        "    main_axes.hist(signal_x, bins=bin_edges, bottom=mc_x_tot, \n",
        "                   weights=signal_weights, color=signal_color,\n",
        "                   label=r'Higgs ($m_H$ = 125 GeV)')\n",
        "    \n",
        "    # plot the statistical uncertainty\n",
        "    main_axes.bar(bin_centres, # x\n",
        "                  2*mc_x_err, # heights\n",
        "                  alpha=0.5, # half transparency\n",
        "                  bottom=mc_x_tot-mc_x_err, color='none', \n",
        "                  hatch=\"////\", width=step_size, label='Stat. Unc.' )\n",
        "\n",
        "    # set the x-limit of the main axes\n",
        "    main_axes.set_xlim( left=xmin, right=xmax ) \n",
        "    \n",
        "    # separation of x axis minor ticks\n",
        "    main_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
        "    \n",
        "    # set the axis tick parameters for the main axes\n",
        "    main_axes.tick_params(which='both', # ticks on both x and y axes\n",
        "                          direction='in', # Put ticks inside and outside the axes\n",
        "                          top=True, # draw ticks on the top axis\n",
        "                          right=True ) # draw ticks on right axis\n",
        "    \n",
        "    # x-axis label\n",
        "    main_axes.set_xlabel(r'2-lepton invariant mass $m_{T}$ [GeV]',\n",
        "                        fontsize=13, x=1, horizontalalignment='right' )\n",
        "    \n",
        "    # write y-axis label for main axes\n",
        "    main_axes.set_ylabel('Events / '+str(step_size)+' GeV',\n",
        "                         y=1, horizontalalignment='right') \n",
        "    \n",
        "    # set y-axis limits for main axes\n",
        "    main_axes.set_ylim( bottom=0, top=np.amax(data_x)*1.6 )\n",
        "    \n",
        "    # add minor ticks on y-axis for main axes\n",
        "    main_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
        "\n",
        "    # Add text 'ATLAS Open Data' on plot\n",
        "    plt.text(0.05, # x\n",
        "             0.93, # y\n",
        "             'ATLAS Open Data', # text\n",
        "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
        "             fontsize=13 ) \n",
        "    \n",
        "    # Add text 'for education' on plot\n",
        "    plt.text(0.05, # x\n",
        "            0.76, # y\n",
        "             'Reproduced by: Brayan E. Castiblanco O.', # text\n",
        "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
        "             style='italic',\n",
        "             fontsize=8 ) \n",
        "    \n",
        "    # Add energy and luminosity\n",
        "    lumi_used = str(L*fraction) # luminosity to write on the plot\n",
        "    plt.text(0.05, # x\n",
        "             0.88, # y\n",
        "             '$\\sqrt{s}$=13 TeV,$\\int$L dt = '+lumi_used+' fb$^{-1}$', # text\n",
        "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
        "    \n",
        "    # Add a label for the analysis carried out\n",
        "    plt.text(0.05, # x\n",
        "             0.82, # y\n",
        "             r'$H \\rightarrow WW^* \\rightarrow e\\nu \\mu\\nu$', # text \n",
        "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
        "\n",
        "    # draw the legend\n",
        "    main_axes.legend( frameon=False ) # no box around the legend\n",
        "    \n",
        "    return"
      ],
      "metadata": {
        "id": "mN8eACIsA4Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the function to plot the data"
      ],
      "metadata": {
        "id": "RkcE0iolDDjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data(data)"
      ],
      "metadata": {
        "id": "vXN7C3ZoDE-P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}